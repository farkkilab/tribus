{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.metrics import v_measure_score, homogeneity_score, completeness_score\n",
    "from tribus import marker_expression\n",
    "from minisom import MiniSom\n",
    "\n",
    "from hyperopt import fmin, tpe, hp, Trials, STATUS_OK\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_type = \"CODEX\"\n",
    "Q = 0.999\n",
    "Logic = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(124623, 36)\n",
      "(122352, 36)\n",
      "['Apoptotic' 'B-cells' 'CD11c+APC' 'CD11c+CD163+IBA1+Macrophages'\n",
      " 'CD11c+IBA1+Macrophages' 'CD163+IBA1+Macrophages' 'CD163+Macrophages'\n",
      " 'CD4+effectorT-cells' 'CD8+T-cells' 'EMT' 'Endothelia' 'Epithelial'\n",
      " 'FOXP3+CD4+Tregs' 'Functional_epithelial' 'Functional_stroma' 'High-P21'\n",
      " 'High-Vimentin' 'High-proliferative_Stroma' 'IBA1+Macrophages'\n",
      " 'Low-vimentin' 'Low_eccentricity' 'Mesenchymal'\n",
      " 'Non-proliferative_Stroma' 'Other' 'Proliferating EMT'\n",
      " 'Proliferating epithelial' 'Proliferative_Stroma']\n",
      "['B-cells' 'CD4 T cells' 'CD8 T cells' 'Myeloid' 'Stromal' 'T Reg cells'\n",
      " 'Tumor' 'other_Global']\n",
      "TMA\n",
      "41\n"
     ]
    }
   ],
   "source": [
    "if data_type == \"CODEX\": \n",
    "\n",
    "    # read in CODEX donor 004 cl dataset\n",
    "    sample_data = pd.read_csv('C:\\\\Users\\\\Public\\\\Farkkila_lab_datasets\\\\Tribus\\\\Test_case_data\\\\STELLAR\\\\input_data\\\\STELLAR_data_donor_004_upperlevel_CL.csv',low_memory=False)\n",
    "    print(np.shape(sample_data))\n",
    "\n",
    "    #  perform always outlier truncation, set the maximum to the 99。9 percentile\n",
    "    cols = ['MUC2', 'SOX9', 'MUC1', 'CD31', 'Synapto', 'CD49f', 'CD15',\n",
    "        'CHGA', 'CDX2', 'ITLN1', 'CD4', 'CD127', 'Vimentin', 'HLADR',\n",
    "        'CD8', 'CD11c', 'CD44', 'CD16', 'BCL2', 'CD3', 'CD123', 'CD38',\n",
    "        'CD90', 'aSMA', 'CD21', 'NKG2D', 'CD66', 'CD57', 'CD206', 'CD68',\n",
    "        'CD34', 'aDef5', 'CD7', 'CD36', 'CD138', 'CD45RO', 'Cytokeratin',\n",
    "        'CK7', 'CD117', 'CD19', 'Podoplanin', 'CD45', 'CD56', 'CD69',\n",
    "        'Ki67', 'CD49a', 'CD163', 'CD161']\n",
    "\n",
    "    df = pd.ExcelFile(\"C:\\\\Users\\\\Public\\\\Farkkila_lab_datasets\\\\Tribus\\\\Test_case_data\\\\STELLAR\\\\stellar_logic_gate_cl_benchmarking.xlsx\")\n",
    "    logic = pd.read_excel(df, df.sheet_names, index_col=0)\n",
    "    markers = list(logic[\"Global\"].index)\n",
    "\n",
    "    celltype1 = \"cell_type_A\"\n",
    "    celltype2 = \"cell_type_upperlevel\"\n",
    "\n",
    "elif data_type == \"TMA\": \n",
    "\n",
    "    # read input files\n",
    "    # no outlier filtering\n",
    "    sample_data = pd.read_csv(\"C:\\\\Users\\\\Public\\\\Farkkila_lab_datasets\\\\Tribus\\\\Test_case_data\\\\TMA_works\\\\TMA_all_data_labeled.csv\")\n",
    "    print(np.shape(sample_data))\n",
    "\n",
    "    #  perform always outlier truncation, set the maximum to the 99。9 percentile\n",
    "    cols = ['CD11c', 'CD1c', 'CD4', 'CD3d', 'CD20', 'CD163',\n",
    "        'CD8a', 'cCasp3', 'pSTAT1', 'Ki67', 'PDL1', 'IBA1', 'FOXP3', 'PD1',\n",
    "        'Ecadherin', 'vimentin', 'CD31', 'P21', 'CK7', 'CD45']\n",
    "    \n",
    "    celltype1 = \"CellType\"\n",
    "    celltype2 = \"merged_labels\"\n",
    "\n",
    "    df = pd.ExcelFile(\"C:\\\\Users\\\\Public\\\\Farkkila_lab_datasets\\\\Tribus\\\\Test_case_data\\\\TMA_works\\\\cell_type_descriptions.xlsx\")\n",
    "    logic = pd.read_excel(df, df.sheet_names, index_col=0)\n",
    "    markers = list(logic[\"Global\"].index)\n",
    "    \n",
    "elif data_type == \"CyTOF\": \n",
    "\n",
    "    # read input files\n",
    "    # no outlier filtering\n",
    "    sample_data = pd.read_csv(\"C:\\\\Users\\\\Public\\\\Farkkila_lab_datasets\\\\Tribus\\\\Test_case_data\\\\CyTOF_TNBC\\\\input_data\\\\TNBC_Data_origin.csv\")\n",
    "    print(np.shape(sample_data))\n",
    "\n",
    "    #  perform always outlier truncation, set the maximum to the 99。9 percentile\n",
    "    cols = ['Vimentin', 'SMA','FoxP3', 'Lag3', 'CD4', \n",
    "            'CD16', 'CD56', 'PD1', 'CD31','PD-L1', \n",
    "            'EGFR', 'Ki67', 'CD209', 'CD11c', 'CD138', \n",
    "            'CD163','CD68', 'CD8', 'CD3', 'IDO', \n",
    "            'Keratin17', 'CD63','CD45RO', 'CD20', 'p53', \n",
    "            'Beta catenin', 'HLA-DR', 'CD11b', 'CD45',\n",
    "            'Pan-Keratin', 'MPO','Keratin6']\n",
    "    \n",
    "    celltype1 = \"DetailedGroup\"\n",
    "    celltype2 = \"Group\"\n",
    "\n",
    "    df = pd.ExcelFile(\"C:\\\\Users\\\\Public\\\\Farkkila_lab_datasets\\\\Tribus\\\\Test_case_data\\\\CyTOF_TNBC\\\\logic_gate.xlsx\")\n",
    "    logic = pd.read_excel(df, df.sheet_names, index_col=0)\n",
    "    markers = list(logic[\"Global\"].index)\n",
    "\n",
    "Q = sample_data[cols].quantile(Q)\n",
    "sample_data = sample_data[~((sample_data[cols] > Q)).any(axis=1)]\n",
    "print(np.shape(sample_data))\n",
    "sample_data[cols].describe()\n",
    "\n",
    "labels_true_1 = sample_data[celltype1]\n",
    "print(np.unique(labels_true_1))\n",
    "labels_true_2 = sample_data[celltype2]\n",
    "print(np.unique(labels_true_2))\n",
    "\n",
    "grid_size = int(np.sqrt(np.sqrt(len(sample_data)) * 5))\n",
    "print(data_type)\n",
    "print(grid_size)\n",
    "\n",
    "if logic == \"FALSE\":    \n",
    "    marker_data = np.arcsinh(sample_data[cols]).to_numpy()\n",
    "else: \n",
    "    marker_data = np.arcsinh(sample_data[markers]).to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [ 500 / 500 ] 100% - 0:00:00 left \n",
      " quantization error: 0.2632484137640619\n",
      "5\n",
      "0.12131178703517663\n",
      "0.23088096213841064\n",
      "0.4607989484400614\n",
      "0.37766716300391173\n"
     ]
    }
   ],
   "source": [
    "# Initialization and training\n",
    "som_shape = (grid_size, grid_size)\n",
    "som = MiniSom(som_shape[0], som_shape[1], marker_data.shape[1], sigma=.5, learning_rate=.5,\n",
    "              neighborhood_function='gaussian')\n",
    "\n",
    "som.train_batch(marker_data, 500, verbose=True)\n",
    "\n",
    "# each neuron represents a cluster\n",
    "winner_coordinates = np.array([som.winner(x) for x in marker_data]).T\n",
    "# with np.ravel_multi_index we convert the bidimensional\n",
    "# coordinates to a monodimensional index\n",
    "cluster_index = np.ravel_multi_index(winner_coordinates, som_shape)\n",
    "\n",
    "print(len(np.unique(cluster_index)))\n",
    "\n",
    "# A clustering result satisfies homogeneity if all of its clusters contain only data points which are members of a single class.\n",
    "print(homogeneity_score(labels_true_1, cluster_index))\n",
    "print(homogeneity_score(labels_true_2, cluster_index))\n",
    "print(completeness_score(labels_true_1, cluster_index))\n",
    "print(completeness_score(labels_true_2, cluster_index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_som(x, y, input_len, sigma, learning_rate, iterations): \n",
    "    som = MiniSom(x=x, \n",
    "                  y=y, \n",
    "                  input_len = input_len, \n",
    "                  sigma = sigma, \n",
    "                  learning_rate = learning_rate)\n",
    "    som.random_weights_init(marker_data)\n",
    "    # training\n",
    "    start_time = time.time()\n",
    "    som.train_random(marker_data, iterations)\n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(elapsed_time, \" seconds\")\n",
    "    return som"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x is 41\n",
      "8.86020294720663                                      \n",
      "8.9822229798672                                                               \n",
      "8.897362369950365                                                             \n",
      "8.947244512913256                                                             \n",
      "8.89077440911263                                                              \n",
      "8.864929767196456                                                             \n",
      "8.885122775151627                                                             \n",
      "8.848506465478753                                                             \n",
      "8.900297765448503                                                              \n",
      "8.844399738149017                                                              \n",
      "8.946221087161417                                                               \n",
      "8.875424649474915                                                               \n",
      "8.90182505202143                                                                \n",
      "8.912799371282365                                                               \n",
      "8.967030686529753                                                               \n",
      "100%|██████████| 15/15 [00:36<00:00,  2.46s/trial, best loss: 8.844399738149017]\n",
      "best: {'learning_rate': 4.36919546568751, 'sig': 1.521233099971735}\n",
      "0 <hyperopt.base.Trials object at 0x000002C6BE348670>\n",
      "1 <hyperopt.base.Trials object at 0x000002C6BE348670>\n"
     ]
    }
   ],
   "source": [
    "# set hyperparameters\n",
    "rows_data = marker_data.shape[0]\n",
    "x = int(np.sqrt(5 * np.sqrt(rows_data)))\n",
    "print(\"x is {}\".format(x))\n",
    "y = x\n",
    "input_len = marker_data.shape[1]\n",
    "sigma = 0.003\n",
    "learning_rate = 5\n",
    "iterations = 100\n",
    "\n",
    "space = {\n",
    "    'sig': hp.uniform(\"sig\", 0.001, 5), \n",
    "    'learning_rate': hp.uniform(\"learning_rate\", 0.001, 5),\n",
    "}\n",
    "\n",
    "def som_fn(space): \n",
    "    sig = space['sig']\n",
    "    learning_rate = space['learning_rate']\n",
    "    val = MiniSom(x=x, \n",
    "                  y=x, \n",
    "                  input_len=input_len,\n",
    "                  sigma=sig,\n",
    "                  learning_rate=learning_rate\n",
    "                  ).quantization_error(marker_data)\n",
    "    print(val)\n",
    "    return{'loss': val, 'status': STATUS_OK}\n",
    "\n",
    "trials = Trials()\n",
    "best = fmin(fn = som_fn, \n",
    "            space=space, \n",
    "            algo = tpe.suggest, \n",
    "            max_evals=15, \n",
    "            trials=trials)\n",
    "\n",
    "print('best: {}'.format(best))\n",
    "\n",
    "for i, trial in enumerate(trials.trials[:2]): \n",
    "    print(i, trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41 41 1.521233099971735 4.36919546568751\n"
     ]
    }
   ],
   "source": [
    "sigma = best['sig']\n",
    "learning_rate = best['learning_rate']\n",
    "print(x, y, sigma, learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07358479499816895  seconds\n",
      "1421\n",
      "0.464305687282738\n",
      "0.5701669235664616\n",
      "0.1957020433679857\n",
      "0.10349181408968848\n"
     ]
    }
   ],
   "source": [
    "som = train_som(x, y, input_len, sigma, learning_rate, iterations=500)\n",
    "\n",
    "# each neuron represents a cluster\n",
    "winner_coordinates = np.array([som.winner(x) for x in marker_data]).T\n",
    "# with np.ravel_multi_index we convert the bidimensional\n",
    "# coordinates to a monodimensional index\n",
    "som_shape = (grid_size, grid_size)\n",
    "cluster_index = np.ravel_multi_index(winner_coordinates, som_shape)\n",
    "\n",
    "print(len(np.unique(cluster_index)))\n",
    "\n",
    "# A clustering result satisfies homogeneity if all of its clusters contain only data points which are members of a single class.\n",
    "print(homogeneity_score(labels_true_1, cluster_index))\n",
    "print(homogeneity_score(labels_true_2, cluster_index))\n",
    "print(completeness_score(labels_true_1, cluster_index))\n",
    "print(completeness_score(labels_true_2, cluster_index))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tribus_new",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
